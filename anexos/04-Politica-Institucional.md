
# Anexo 04: Política Institucional de Uso Responsable de Inteligencia Artificial

*Plantilla Marco para Organizaciones Públicas y Privadas*

---

### Introducción: De la Guía a la Política

Esta plantilla marco establece los principios y obligaciones para el uso responsable de Inteligencia Artificial (IA) en organizaciones públicas y privadas. Su propósito es servir como base adaptable, integrando conceptos de gobernanza, ética y seguridad derivados de la obra *Inteligencia Artificial Aplicada*, especialmente de las Guías 07, 10 y 12, junto con los marcos legales y de transparencia aplicables.

---

## 1. Propósito

Esta política establece los principios, criterios y responsabilidades que regulan el uso seguro, responsable y ético de la IA en la organización.

Su objetivo es garantizar que la IA:

* sirva al interés público o valor organizacional,
* aumente la eficiencia institucional,
* proteja derechos y seguridad,
* mantenga la confianza ciudadana o del cliente,
* y complemente —sin reemplazar— el criterio, el juicio y la responsabilidad exclusivamente humanos.

---

# 2. Alcance

Esta política aplica a:

* todas las unidades de la organización,
* todos los funcionarios, colaboradores y contratistas,
* y todos los terceros que diseñen, operen o utilicen herramientas de IA para fines institucionales.

---

# **Definición de “Sistema de IA”**

Para efectos de esta política, un **Sistema de IA** es:

> “Cualquier tecnología que usa datos para hacer inferencias y generar resultados, como predicciones, recomendaciones, clasificaciones o contenidos, con un grado de autonomía.”

Incluye:
modelos de machine learning, IA generativa, sistemas predictivos, agentes autónomos, modelos embebidos, herramientas RAG.

Excluye:
fórmulas de hojas de cálculo, automatizaciones basadas en reglas fijas, dashboards de BI sin inferencia.

---

# **Supervisión Humana Significativa**

**Supervisión Humana Significativa** es la intervención responsable de una persona con competencia y autoridad suficiente para revisar, validar, corregir o detener el resultado de un sistema de IA antes de que genere un impacto material.

La responsabilidad final es siempre humana.

---

# **3. Principios Rectores**

Todo uso de IA se regirá por los siguientes principios:

### **Legalidad y Proporcionalidad**

Cumplimiento normativo y uso proporcional a la necesidad. La IA no es siempre la opción adecuada.

### **Criterio Humano (Delegar, No Abdicar)**

La IA automatiza tareas de **Sistema 1**; la organización gobierna desde **Sistema 2**.
Toda decisión de impacto requiere supervisión humana significativa.
La responsabilidad recae siempre en personas.

### **Gobernanza de la Fuente (Combustible Limpio)**

Un sistema de IA depende de la calidad, integridad y actualización de sus datos.
La organización se compromete a mantener estándares de gobernanza de datos robustos.

### **Transparencia y Licencia Social**

La ciudadanía, clientes o usuarios deben saber cuándo se usa IA, con qué finalidad y bajo qué controles.

### **Equidad y No Discriminación**

Los sistemas deben minimizar sesgos y evitar decisiones discriminatorias.

### **Privacidad desde el Diseño**

Principios de minimización, proporcionalidad y resguardo de datos personales.

### **Seguridad y Resiliencia**

Los sistemas deben ser robustos frente a errores, fallas técnicas o ataques (como inyección de prompts).

### **Antifragilidad y Gestión del Riesgo**

La IA no debe introducir fragilidad sistémica.
Se evaluarán riesgos de errores catastróficos, acumulativos o de difícil detección (“Cisnes Negros”).

### **Trazabilidad y Auditabilidad**

Todos los procesos que incluyan IA deben permitir reconstruir decisiones, verificar fuentes y auditar resultados.
Sin trazabilidad, no hay responsabilidad.

---

# **4. Directriz Central: IA Generativa y Agentes Autónomos**

### **Finalidad Permitida**

La IA se utiliza principalmente para tareas operativas o repetitivas (S1), permitiendo que el personal se concentre en tareas de criterio, análisis, diseño y supervisión (S2).

### **Principios Específicos**

* **Validación obligatoria:** Ningún contenido de IA se utiliza sin verificación humana en decisiones de impacto.
* **Basura Elocuente:** Se asume que la IA generativa puede producir resultados persuasivos pero incorrectos; se verifica todo.
* **Prohibición de datos sensibles:** No se permite ingresar datos personales sensibles o confidenciales en herramientas no aprobadas.
* **Transparencia:** Todo chatbot o asistente debe identificarse como IA.
* **Agentes Autónomos:** Solo pueden operar con límites claros, registro de actividades y supervisión activa.

---

# **5. Gobernanza, Roles y Responsabilidades**

### **Dueño de la Política**

Máxima autoridad responsable de la vigencia, actualización y patrocinio institucional de esta política.

### **Comité de Gobernanza de IA**

Revisa proyectos de alto impacto, gestiona riesgos y aprueba excepciones justificadas.

### **Dueño del Sistema de IA**

Responsable del ciclo de vida del sistema de IA, documentación, trazabilidad y cumplimiento de esta política.

### **Monitor de Cumplimiento**

Audita el cumplimiento de la política, verifica que los sistemas estén registrados y que existan evidencias de supervisión.

### **Usuarios Finales**

Actúan como validadores y responsables de revisar, corregir y reportar resultados generados por IA. Deben reportar incidentes y cumplir esta política.

---

# **6. Cumplimiento y Sanciones**

El incumplimiento de esta política constituye una falta al deber profesional o a la probidad (según corresponda al tipo de organización).

Constituye negligencia profesional o falta grave:

* usar resultados de IA sin validación humana significativa,
* automatizar decisiones críticas sin controles,
* utilizar herramientas de IA no aprobadas (“IA en la Sombra”),
* ingresar datos sensibles o confidenciales en plataformas no autorizadas,
* evadir supervisión o trazabilidad requerida.

La responsabilidad por decisiones asistidas con IA recae siempre en la persona que las adopta.

---

# **7. Revisión y Vigencia**

Esta política será revisada:

* **una vez al año**, y
* de manera **extraordinaria** ante incidentes relevantes, cambios regulatorios o tecnologías emergentes que modifiquen el riesgo institucional.

Su vigencia comienza desde la fecha de aprobación formal.

---

# **Guía de Adaptación para el Sector Privado**

Para adopción en empresas privadas, se recomienda:

* reemplazar “interés público” por “valor de negocio / confianza del cliente”,
* ajustar la legalidad a marcos corporativos, PI y protección del consumidor,
* reemplazar “probidad administrativa” por responsabilidad laboral contractual,
* mantener idénticos los principios de transparencia, seguridad y trazabilidad.

---

**Fin del Documento**

Versión 1.0 – 2025

---
  <div style="display: flex; justify-content: space-between; font-size: 0.9em; padding-top: 10px;">
    <div>
      <a href="./03-Plantillas-Recursos.html">« Anexo Anterior</a>
    </div>
    <div>
      <a href="../">Volver al Índice</a>
    </div>
    <div>
      <a href="./05-Modelos-Mercado.html">Siguiente Anexo »</a>
    </div>
  </div>